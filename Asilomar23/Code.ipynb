{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LoRa Signal Classification"
      ],
      "metadata": {
        "id": "ALRn6NJOB-Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_INPUT_SHAPE = (1024, 1)\n",
        "MODEL_OUTPUT_SHAPE = (18,)\n",
        "\n",
        "F_SAMP = int(1e6)\n",
        "F_MAX = 250000\n",
        "WINDOW_SIZE = 2**7\n",
        "WINDOW_OVERLAP = WINDOW_SIZE // 2\n",
        "\n",
        "BW_VALUES = [125000, 250000, 500000]\n",
        "SF_VALUES = [7, 8, 9, 10, 11, 12]\n",
        "\n",
        "SNR_MIN = -15\n",
        "SNR_MAX = 20\n",
        "SNR_STEP = 2\n",
        "PATH_RESULTS = '/content/Results'\n",
        "PATH_PREAMBLE_REFERENCE_IQ = '/content/Preamble_symbols'\n",
        "\n",
        "PATH_TRAIN_DATASET = '/content/Train_Dataset'\n",
        "PATH_VAL_DATASET = '/content/Validation_Dataset'\n",
        "PATH_FIGURES = '/content/Figures'\n",
        "FONT_SIZE = 16\n",
        "FONT_SIZE_LEGEND = 12\n",
        "PATH_FIGURES = '/content/Figures'"
      ],
      "metadata": {
        "id": "emikjod_kTff"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "A0ToEmLbkKXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.signal import spectrogram\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.stats import t"
      ],
      "metadata": {
        "id": "Nz6OF0XJkI8n"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utility"
      ],
      "metadata": {
        "id": "d0YSwBgxs8im"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(config):\n",
        "  one_hot_label = np.zeros(18)\n",
        "  one_hot_label[config] = 1\n",
        "  return one_hot_label"
      ],
      "metadata": {
        "id": "nJOZPxBHs9kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset"
      ],
      "metadata": {
        "id": "KU3ll2o6tNo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_iq_file(filepath):\n",
        "    with open(filepath, \"rb\") as f:\n",
        "        iq_samples = np.fromfile(f, dtype=np.complex64)\n",
        "    return iq_samples\n",
        "\n",
        "def read_IF_sample(file_path):\n",
        "  IF_sample = np.load(file_path)[-MODEL_INPUT_SHAPE[0]:]\n",
        "  return IF_sample\n",
        "\n",
        "def get_reference_iq_samples(bandwidth, spread_factor):\n",
        "  iq_file_path = os.path.join(PATH_PREAMBLE_REFERENCE_IQ,\n",
        "                                  'PR_Ref_BW{}_SF{}.bin'.format(\n",
        "                                      BW_VALUES.index(bandwidth),\n",
        "                                      spread_factor))\n",
        "  return read_iq_file(iq_file_path)\n",
        "\n",
        "def pad_signal(signal_IQ):\n",
        "  signal_len = signal_IQ.shape[0]\n",
        "  input_length= (MODEL_INPUT_SHAPE[0]+1)*WINDOW_OVERLAP\n",
        "\n",
        "  padded_signal = np.zeros(input_length, dtype= np.complex64)\n",
        "  if signal_len <= input_length:\n",
        "    padded_signal[-signal_len:] = signal_IQ\n",
        "  else:\n",
        "    padded_signal = signal_IQ[-input_length:]\n",
        "  return padded_signal\n",
        "\n",
        "def add_gaussian_noise(signal, snr_db):\n",
        "    non_zero_samples = np.nonzero(signal)[0]\n",
        "    first_non_zero = non_zero_samples[0] if len(non_zero_samples) > 0 else 0\n",
        "    last_non_zero = non_zero_samples[-1] if non_zero_samples[-1] < len(\n",
        "        signal) else len(signal)-1\n",
        "    signal_power = np.mean(np.abs(signal[first_non_zero:last_non_zero+1]) ** 2)\n",
        "    snr = 10 ** (snr_db / 10.0)\n",
        "    noise_power = signal_power / snr\n",
        "    noise = np.sqrt(noise_power / 2) * (np.random.randn(*signal.shape) + 1j * np.random.randn(*signal.shape))\n",
        "    noisy_signal = signal + noise\n",
        "    return noisy_signal\n",
        "\n",
        "def simulate_iq_samples(bandwidth, spread_factor, snr_db):\n",
        "    IQ_ref = get_reference_iq_samples(bandwidth, spread_factor)\n",
        "    IQ_noisy = add_gaussian_noise(pad_signal(IQ_ref), snr_db)\n",
        "    return IQ_noisy\n",
        "\n",
        "def compute_spectrogram(IQ_samples):\n",
        "  Sxx =  spectrogram(IQ_samples, F_SAMP,window= 'hann',\n",
        "                             nperseg= WINDOW_SIZE,noverlap= WINDOW_OVERLAP,\n",
        "                             return_onesided= False)[2]\n",
        "  Sxx = np.vstack([Sxx[Sxx.shape[0]//2:], Sxx[:Sxx.shape[0]//2]])\n",
        "  Sxx = Sxx[WINDOW_SIZE//4:-WINDOW_SIZE//4, :]\n",
        "  Sxx = (Sxx - np.min(Sxx))/(np.max(Sxx)-np.min(Sxx))\n",
        "  return Sxx\n",
        "\n",
        "def compute_inst_freq(spec_sample):\n",
        "  spec_sample = spec_sample**4\n",
        "  f_bins = np.linspace(-F_MAX, F_MAX, num=spec_sample.shape[0]+1)[:-1]\n",
        "  weighted_sum = np.sum(spec_sample * f_bins[:, np.newaxis], axis=0)\n",
        "  total_power = np.sum(spec_sample, axis=0)\n",
        "  IF_sample = np.clip((weighted_sum / total_power)/F_MAX, -1, 1)[:, np.newaxis]\n",
        "  return IF_sample\n",
        "\n",
        "def simulate_IF_sample(config, snr):\n",
        "  bandwidth, spread_factor = BW_VALUES[config//6], SF_VALUES[config%6]\n",
        "  IQ_samples = simulate_iq_samples(bandwidth, spread_factor, snr)\n",
        "  spec_sample = compute_spectrogram(IQ_samples)\n",
        "  IF_sample = compute_inst_freq(spec_sample)[-MODEL_INPUT_SHAPE[0]:]\n",
        "  return IF_sample\n",
        "\n",
        "def create_dataset(path, snr_range, count):\n",
        "  for snr in snr_range:\n",
        "    for config in range(18):\n",
        "      for i in range(count):\n",
        "        file_name = f'SNR{encode_snr(snr)}C{config:02}T{i:02}.npy'\n",
        "        file_path = os.path.join(path, file_name)\n",
        "        IF_sample = simulate_IF_sample(config, snr)\n",
        "        np.save(file_path, IF_sample)"
      ],
      "metadata": {
        "id": "h1Wt5pF5GtkC"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_snr(snr):\n",
        "    if snr < 0:\n",
        "        snr_sign = 1\n",
        "        snr_mag = int(abs(snr) * 100)\n",
        "    else:\n",
        "        snr_sign = 0\n",
        "        snr_mag = int(snr * 100)\n",
        "    encoded_snr = snr_sign * 10000 + snr_mag\n",
        "    return f\"{encoded_snr:05}\"\n",
        "\n",
        "def decode_snr(snr):\n",
        "  # Decode SNR from file name (sign: 0/1, magnitude: 0.00-99.99)\n",
        "  snr_sign, snr_mag = divmod(int(snr), 10000)\n",
        "  snr = (-1)*(snr_mag/100) if snr_sign else snr_mag/100\n",
        "  return snr\n",
        "\n",
        "def parse_file_name(file_path):\n",
        "  #filename format 'SNR00000C00T00.npy'\n",
        "  file_name = os.path.basename(file_path)\n",
        "  match = re.search(r'SNR(\\d{5})C(\\d{2})T(\\d{2}).npy', file_name)\n",
        "  if match:\n",
        "      snr = decode_snr(match.group(1))\n",
        "      config = int(match.group(2))\n",
        "      index = int(match.group(3))\n",
        "      return snr, config, index"
      ],
      "metadata": {
        "id": "GVNik3JMtOcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "p4MeMi5wFj1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = Sequential([\n",
        "      Flatten(input_shape=MODEL_INPUT_SHAPE),\n",
        "      Dense(16, activation='tanh'),\n",
        "      Dense(16, activation='tanh'),\n",
        "      Dropout(0.5),\n",
        "      Dense(18, activation='softmax')\n",
        "  ])\n",
        "  model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def load_model(model_name):\n",
        "  path_model = os.path.join(PATH_MODELS, model_name)\n",
        "  return tf.keras.models.load_model(path_model)\n",
        "\n",
        "def save_model(model, model_name):\n",
        "  path_model = os.path.join(PATH_MODELS, model_name)\n",
        "  model.save(path_model)"
      ],
      "metadata": {
        "id": "UwY_SUn-FmfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training"
      ],
      "metadata": {
        "id": "HFsZPYfiCPpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_generator(files_list, batch_size):\n",
        "  while True:\n",
        "    X, y = [], []\n",
        "    sample_count = 0\n",
        "    for file_path in files_list:\n",
        "      sample = read_IF_sample(file_path)\n",
        "      config = parse_file_name(os.path.basename(file_path))[1]\n",
        "      label = encode_label(config)\n",
        "      X.append(sample)\n",
        "      y.append(label)\n",
        "      sample_count += 1\n",
        "      if sample_count == batch_size:\n",
        "          yield np.array(X), np.array(y)\n",
        "          X, y = [], []\n",
        "          sample_count = 0\n",
        "\n",
        "def train_model_from_files(model, train_data, validation_data):\n",
        "  batch_size = 8\n",
        "  train_data_gen = data_generator(train_data, batch_size)\n",
        "  val_data_gen = data_generator(validation_data, batch_size)\n",
        "  model.fit(train_data_gen, epochs=5, steps_per_epoch=len(train_data)//batch_size,\n",
        "            validation_data=val_data_gen, validation_steps=len(validation_data)//batch_size,\n",
        "            verbose=1)\n",
        "  return model\n",
        "def evaluate_model(model, path_val_dataset=PATH_VAL_DATASET, snr_range=list(range(SNR_MIN, SNR_MAX, SNR_STEP)), size = 20):\n",
        "  results_config = []\n",
        "  for config in range(18):\n",
        "    results_snr = []\n",
        "    for snr in snr_range:\n",
        "      X = []\n",
        "      y = np.array([encode_label(config)]*size)\n",
        "      for i in range(size):\n",
        "        file_name = f'SNR{encode_snr(snr)}C{config:02}T{i:02}.npy'\n",
        "        sample = read_IF_sample(os.path.join(path_val_dataset, file_name))\n",
        "        X.append(sample)\n",
        "      X = np.array(X)\n",
        "      acc = model.evaluate(X,y)[1]\n",
        "      results_snr.append(acc)\n",
        "    results_config.append(np.array(results_snr))\n",
        "  return np.array(results_config)"
      ],
      "metadata": {
        "id": "ft5pxHUpeeGI"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting"
      ],
      "metadata": {
        "id": "AGyzZRJ3E_Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def select_configs(results, config_choice):\n",
        "    return results[:, config_choice, :].reshape(-1, results.shape[-1])\n",
        "\n",
        "def plot_results(results, snr_range, label=None, cf = 0.95):\n",
        "    n = results.shape[0]\n",
        "    means = np.mean(results, axis=0)\n",
        "    stds = np.std(results, axis=0)\n",
        "    h = stds * t.ppf((1 + cf) / 2, n - 1) / np.sqrt(n)\n",
        "    cis = np.vstack((means - h, means + h))\n",
        "    plt.plot(snr_range, means, 'o-', markersize= 3, label=label)\n",
        "    plt.fill_between(snr_range, cis[0, :], cis[1, :], alpha=0.2)#, label=f'Confidence {int(cf*100)}%')\n",
        "\n",
        "def display_results_BW(results, snr_range, path_save=None):\n",
        "\n",
        "    BW_values = [125, 250, 500]\n",
        "    plt.figure()\n",
        "    plt.rc('font', size=FONT_SIZE)\n",
        "    plt.grid()\n",
        "    plt.ylim(0, 100)\n",
        "    plt.yticks(range(0, 101, 10), fontsize=FONT_SIZE_LEGEND)\n",
        "    plt.xticks(snr_range[::2], fontsize=FONT_SIZE_LEGEND)\n",
        "    plt.title('(3) Accuracy by Bandwidth', fontsize=FONT_SIZE)\n",
        "    plt.xlabel('Signal to Noise Ratio (dB)')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    for idx, bw in enumerate(BW_values):\n",
        "        config_choice = [idx*6+i for i in range(6)]\n",
        "        reshaped_results = select_configs(results, config_choice)\n",
        "        plot_results(reshaped_results, snr_range, label=f'BW {bw} kHz')\n",
        "    plt.legend(loc='lower right', fontsize=FONT_SIZE_LEGEND)\n",
        "    if path_save is not None:\n",
        "        plt.savefig(os.path.join(path_save, 'fig_acc_bw.pdf'))\n",
        "    plt.show()\n",
        "\n",
        "def display_results_SF(results, snr_range, path_save=None):\n",
        "\n",
        "    SF_values = [7, 8, 9, 10, 11, 12]\n",
        "    plt.figure()\n",
        "    plt.rc('font', size=FONT_SIZE)\n",
        "    plt.grid()\n",
        "    plt.ylim(0, 100)\n",
        "    plt.yticks(range(0, 101, 10), fontsize=FONT_SIZE_LEGEND)\n",
        "    plt.xticks(snr_range[::2], fontsize=FONT_SIZE_LEGEND)\n",
        "    plt.title('(2) Accuracy by Spreading Factor', fontsize=FONT_SIZE)\n",
        "    plt.xlabel('Signal to Noise Ratio (dB)')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    for idx, sf in enumerate(SF_values):\n",
        "        config_choice = [i*6+idx for i in range(3)]\n",
        "        reshaped_results = select_configs(results, config_choice)\n",
        "        plot_results(reshaped_results, snr_range, label=f'SF {sf}')\n",
        "    plt.legend(loc='lower right', fontsize=FONT_SIZE_LEGEND)\n",
        "    if path_save is not None:\n",
        "        plt.savefig(os.path.join(path_save, 'fig_acc_sf.pdf'))\n",
        "    plt.show()\n",
        "\n",
        "def display_results(results, snr_range, path_save=None):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.rc('font', size=FONT_SIZE)\n",
        "    plt.grid()\n",
        "    plt.ylim(0, 100)\n",
        "    plt.xlim(-16, 22)\n",
        "    plt.yticks(range(0, 101, 10), fontsize=FONT_SIZE_LEGEND)\n",
        "    plt.xticks(snr_range[::2], fontsize=FONT_SIZE_LEGEND)\n",
        "    plt.title('(1) Overall Accuracy', fontsize=FONT_SIZE)\n",
        "    plt.xlabel('Signal to Noise Ratio (dB)')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    results = results.reshape(-1, results.shape[-1])\n",
        "    plot_results(results, snr_range, label='Mean Accuracy')\n",
        "    plt.legend(loc='lower right', fontsize=FONT_SIZE_LEGEND)\n",
        "    if path_save is not None:\n",
        "        plt.savefig(os.path.join(path_save, 'fig_acc.pdf'))\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "t4PpWFqWFBes"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_all_results(results, path=PATH_FIGURES):\n",
        "  snr_range = np.arange(SNR_MIN, SNR_MAX, SNR_STEP)\n",
        "  acc_results =results*100\n",
        "  display_results(acc_results, snr_range, path_save=path)\n",
        "  display_results_SF(acc_results, snr_range, path_save=path)\n",
        "  display_results_BW(acc_results, snr_range, path_save=path)"
      ],
      "metadata": {
        "id": "v0my8lmQUUC-"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simulation"
      ],
      "metadata": {
        "id": "OjsYqwnAB_j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_simulation():\n",
        "  train_dataset = [os.path.join(PATH_TRAIN_DATASET, x) for x in os.listdir(PATH_TRAIN_DATASET) if os.path.isfile(os.path.join(PATH_TRAIN_DATASET, x))]\n",
        "  num_iterations = 30\n",
        "  results = []\n",
        "  snr_range = list(range(SNR_MIN, SNR_MAX+1, SNR_STEP))\n",
        "  for i in range(num_iterations):\n",
        "    print(f'Iteration {i+1}')\n",
        "    train_files, test_files = train_test_split(train_dataset, test_size=0.2,\n",
        "                                               shuffle=True, random_state=40+i)\n",
        "    model = create_model()\n",
        "    model = train_model_from_files(model, train_data= train_files,\n",
        "                                   validation_data= test_files)\n",
        "    results_i = evaluate_model(model, PATH_VAL_DATASET, snr_range)\n",
        "    results.append(results_i)\n",
        "  print('Simulation end!')\n",
        "  return np.array(results)\n"
      ],
      "metadata": {
        "id": "CWIAgLiBCqvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = run_simulation()\n",
        "np.save(os.path.join(PATH_RESULTS, 'simulation_results.npy'), results)\n",
        "display_all_results(results)"
      ],
      "metadata": {
        "id": "qPAa7DBiA_ze"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}